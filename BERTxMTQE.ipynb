{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTxMTQE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E0JR18ycNvOd",
        "U1XS2r0HNYpR",
        "4aJF6f1XM6Hd"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0JR18ycNvOd",
        "colab_type": "text"
      },
      "source": [
        "# Data preproceessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5jRPScz6BJv",
        "colab_type": "text"
      },
      "source": [
        "## Download data and define dataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVhwHNnYJHVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSXU3oQTjM3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "\n",
        "class MT_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, mode, maxlen):\n",
        "\n",
        "      self.mode = mode\n",
        "\n",
        "      #Download data\n",
        "      if not exists('ende_data.zip'):\n",
        "        !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
        "        !unzip ende_data.zip\n",
        "\n",
        "      if self.mode == 'train':\n",
        "        with open(\"./train.ende.src\", \"r\") as ende_src:\n",
        "          src = [line.rstrip('\\n') for line in ende_src]\n",
        "        with open(\"./train.ende.mt\", \"r\") as ende_mt:\n",
        "          mt = [line.rstrip('\\n') for line in ende_mt]\n",
        "        with open(\"./train.ende.scores\", \"r\") as ende_scores:\n",
        "          score = [float(line.rstrip('\\n')) for line in ende_scores]\n",
        "\n",
        "      elif self.mode == 'dev':\n",
        "        with open(\"./dev.ende.src\", \"r\") as ende_src:\n",
        "          src = [line.rstrip('\\n') for line in ende_src]\n",
        "        with open(\"./dev.ende.mt\", \"r\") as ende_mt:\n",
        "          mt = [line.rstrip('\\n') for line in ende_mt]\n",
        "        with open(\"./dev.ende.scores\", \"r\") as ende_scores:\n",
        "          score = [float(line.rstrip('\\n')) for line in ende_scores]\n",
        "\n",
        "      elif self.mode == 'test':\n",
        "        with open(\"./test.ende.src\", \"r\") as ende_src:\n",
        "          src = [line.rstrip('\\n') for line in ende_src]\n",
        "        with open(\"./test.ende.mt\", \"r\") as ende_mt:\n",
        "          mt = [line.rstrip('\\n') for line in ende_mt]\n",
        "\n",
        "      elif self.mode == 'traindev':\n",
        "        with open(\"./train.ende.src\", \"r\") as ende_src:\n",
        "          src_t = [line.rstrip('\\n') for line in ende_src]\n",
        "        with open(\"./train.ende.mt\", \"r\") as ende_mt:\n",
        "          mt_t = [line.rstrip('\\n') for line in ende_mt]\n",
        "        with open(\"./train.ende.scores\", \"r\") as ende_scores:\n",
        "          score_t = [float(line.rstrip('\\n')) for line in ende_scores]\n",
        "        with open(\"./dev.ende.src\", \"r\") as ende_src:\n",
        "          src_d = [line.rstrip('\\n') for line in ende_src]\n",
        "        with open(\"./dev.ende.mt\", \"r\") as ende_mt:\n",
        "          mt_d = [line.rstrip('\\n') for line in ende_mt]\n",
        "        with open(\"./dev.ende.scores\", \"r\") as ende_scores:\n",
        "          score_d = [float(line.rstrip('\\n')) for line in ende_scores]\n",
        "\n",
        "        src = src_t + src_d\n",
        "        mt = mt_t + mt_d\n",
        "        score = score_t + score_d\n",
        "\n",
        "      else:\n",
        "        raise InputError(\"Wrong mode\")\n",
        "      \n",
        "      #Store the contents of the file in a pandas dataframe\n",
        "      if self.mode in ['train', 'dev', 'traindev']:\n",
        "        self.df = pd.DataFrame([src,mt,score]).T\n",
        "        self.df.columns = ['src', 'mt', 'score']\n",
        "      else:\n",
        "        self.df = pd.DataFrame([src,mt]).T\n",
        "        self.df.columns = ['src', 'mt']\n",
        "\n",
        "      self.length = len(self.df)\n",
        "\n",
        "      #Initialize the BERT tokenizer\n",
        "      self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "\n",
        "      #Maximal length of input\n",
        "      self.maxlen = maxlen\n",
        "\n",
        "      #Storing preprocessed inputs\n",
        "      self.token_ids_tensors = []\n",
        "      self.token_type_ids_tensors = []\n",
        "      self.attn_masks = []\n",
        "\n",
        "      #Preprocessing\n",
        "      for index in range(len(self.df)):\n",
        "        src = self.df.loc[index, 'src']\n",
        "        mt = self.df.loc[index, 'mt']\n",
        "\n",
        "        if self.mode in ['train', 'dev', 'traindev']:\n",
        "          score = self.df.loc[index, 'score']\n",
        "        \n",
        "        #Tokenize sentences\n",
        "        tokens_src = self.tokenizer.tokenize(src) \n",
        "        tokens_mt = self.tokenizer.tokenize(mt) \n",
        "\n",
        "        #Insering the CLS and SEP tokens\n",
        "        tokens = ['[CLS]'] + tokens_src + ['[SEP]'] + tokens_mt + ['[SEP]']\n",
        "\n",
        "        #A vector encoding which token belongs to which sentence (values either 0 or 1) \n",
        "        token_type_ids = [0 for _ in range(len(tokens_src)+2)] + [1 for _ in range(len(tokens_mt)+1)]\n",
        "\n",
        "        #Adding padding to keep constant input length\n",
        "        if len(tokens) < self.maxlen:\n",
        "          token_type_ids = token_type_ids + [0 for _ in range(self.maxlen - len(tokens))] #here [PAD] tokens belongs to first sentence\n",
        "          tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "          raise RuntimeError('Sentences are jointly too long for specified maxlen.')\n",
        "\n",
        "        #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens) \n",
        "        \n",
        "        #Converting the lists to a torch tensors\n",
        "        token_ids_tensor = torch.tensor(token_ids) \n",
        "        token_type_ids_tensor = torch.LongTensor(token_type_ids) \n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (token_ids_tensor != 0).long()\n",
        "\n",
        "        self.token_ids_tensors.append(token_ids_tensor)\n",
        "        self.token_type_ids_tensors.append(token_type_ids_tensor)\n",
        "        self.attn_masks.append(attn_mask)\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.length\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      if self.mode in ['train', 'dev', 'traindev']:\n",
        "        return self.token_ids_tensors[i], self.token_type_ids_tensors[i], self.attn_masks[i], self.df.loc[i, 'score']\n",
        "      else:\n",
        "        return self.token_ids_tensors[i], self.token_type_ids_tensors[i], self.attn_masks[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzxzXGas6T73",
        "colab_type": "text"
      },
      "source": [
        "## Create dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skDvY1vls2Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Creating instances of training and validation set\n",
        "train_set = MT_Dataset('train', maxlen = 128)\n",
        "val_set = MT_Dataset('dev', maxlen = 128)\n",
        "test_set = MT_Dataset('test', maxlen = 128)\n",
        "traindev_set = MT_Dataset('traindev', maxlen = 128)\n",
        "\n",
        "#Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 32, shuffle=True, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 32, shuffle=True, num_workers = 5)\n",
        "test_loader = DataLoader(test_set, batch_size = 32, shuffle=False, num_workers = 5)\n",
        "traindev_loader = DataLoader(traindev_set, batch_size = 32, shuffle=True, num_workers = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1XS2r0HNYpR",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLH1SODH64Ej",
        "colab_type": "text"
      },
      "source": [
        "## Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD_aPsSU7siq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "\n",
        "class MTQualityEstimator(nn.Module):\n",
        "\n",
        "  def __init__(self, freeze_bert):\n",
        "    super(MTQualityEstimator, self).__init__()\n",
        "    #Instantiating BERT model object \n",
        "    self.bert_layer = BertModel.from_pretrained('bert-base-multilingual-uncased')\n",
        "    \n",
        "    #Freeze bert layers\n",
        "    if freeze_bert:\n",
        "      for p in self.bert_layer.parameters():\n",
        "        p.requires_grad = False\n",
        "    \n",
        "    #Classification layer\n",
        "    self.fc = nn.Linear(768, 1)\n",
        "\n",
        "  def forward(self, seq, token_type_ids, attn_masks):\n",
        "    '''\n",
        "    Inputs:\n",
        "        -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "        -token_type_ids : Tensor of shape [B, T] encoding segments\n",
        "        -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "    '''\n",
        "\n",
        "    #Feeding the input to BERT model to obtain pooled output representation\n",
        "    _, pool_out = self.bert_layer(seq, token_type_ids = token_type_ids, attention_mask = attn_masks)\n",
        "    \n",
        "\n",
        "    #Feeding cls_rep to the classifier layer\n",
        "    out = 3*torch.tanh(self.fc(pool_out))        #99.7% probability to lie within three standard deviations from the mean for normal distribution\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqjN4D3q72NR",
        "colab_type": "text"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCJalD8U8uHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "model = MTQualityEstimator(freeze_bert = False)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\"\"\" for fine-tuning authors recommend:\n",
        "        batch_size: 16, 32 \n",
        "        learning_rate: 5e-5, 3e-5, 2e-5 \n",
        "        epochs: 2, 3, 4 \"\"\"\n",
        "\n",
        "epochs = 2\n",
        "optimizer = optim.AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcy4b46Z8BC7",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq5WP4uP9Bj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats.stats import pearsonr\n",
        "from torch.nn.functional import mse_loss\n",
        "\n",
        "def check_accuracy(loader, model):\n",
        "  # function for test accuracy on validation and test set\n",
        "  print('Checking accuracy on validation set:')\n",
        "  model.eval()  # set model to evaluation mode\n",
        "  predicted_scores = []\n",
        "  true_scores = []\n",
        "  with torch.no_grad():\n",
        "    for it, (token_ids, token_type_ids, attn_masks, batch_scores) in enumerate(loader):\n",
        "      #Converting to cuda tensors\n",
        "      token_ids, token_type_ids, attn_masks, batch_scores = token_ids.cuda(), token_type_ids.cuda(), attn_masks.cuda(), batch_scores.cuda()\n",
        "\n",
        "      #Forward pass\n",
        "      batch_predict = model(token_ids, token_type_ids, attn_masks).squeeze()\n",
        "\n",
        "      #Aggregate output batches (to calculate correlation over whole dataset later)\n",
        "      predicted_scores.append(batch_predict)\n",
        "      true_scores.append(batch_scores)\n",
        "    \n",
        "  predicted_scores = torch.cat(predicted_scores)\n",
        "  true_scores = torch.cat(true_scores)\n",
        "\n",
        "  pearson = pearsonr(predicted_scores.cpu().numpy(), true_scores.cpu().numpy())\n",
        "\n",
        "  print(f'RMSE: {torch.sqrt(mse_loss(predicted_scores,true_scores))} Pearson {pearson[0]}', '\\n')\n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer, epochs, train_loader, val_loader=None):\n",
        "  model.to('cuda')\n",
        "  for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    for it, (token_ids, token_type_ids, attn_masks, scores) in enumerate(train_loader):\n",
        "      #Clear gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #Converting to cuda tensors\n",
        "      token_ids, token_type_ids, attn_masks, scores = token_ids.cuda(), token_type_ids.cuda(), attn_masks.cuda(), scores.cuda()\n",
        "\n",
        "      #Forward pass\n",
        "      out = model(token_ids, token_type_ids, attn_masks)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(out.squeeze(), scores.float())\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      #Backpropagating the gradients\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization step\n",
        "      optimizer.step()\n",
        "\n",
        "    print(\"Epoch {} complete. Loss: {}\".format(epoch, train_loss/len(train_loader)))\n",
        "    if val_loader:\n",
        "      acc = check_accuracy(val_loader, model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1qlXEBA8OFZ",
        "colab_type": "text"
      },
      "source": [
        "## Validation on hold-out set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fawDvsB39Qan",
        "colab_type": "code",
        "outputId": "892839a2-5d30-4e70-d270-7433916a013a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "train(model, criterion, optimizer, epochs, train_loader, val_loader)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 complete. Loss: 0.6888832414531272\n",
            "Checking accuracy on validation set:\n",
            "RMSE: 0.8664133681433251 Pearson 0.14466003327015103 \n",
            "\n",
            "Epoch 1 complete. Loss: 0.6688045892337141\n",
            "Checking accuracy on validation set:\n",
            "RMSE: 0.8507752228033728 Pearson 0.2039785258195178 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrZWu08h8Vn7",
        "colab_type": "text"
      },
      "source": [
        "## Train with all available data and save predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n988peOJqwl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_predict_test(loader, model):\n",
        "  # compute prediction on unseen data\n",
        "  model.eval()  # set model to evaluation mode\n",
        "  scores = []\n",
        "  with torch.no_grad():\n",
        "    for it, (token_ids, token_type_ids, attn_masks) in enumerate(loader):\n",
        "      #Converting to cuda tensors\n",
        "      token_ids, token_type_ids, attn_masks = token_ids.cuda(), token_type_ids.cuda(), attn_masks.cuda()\n",
        "\n",
        "      #Forward pass\n",
        "      batch_predict = model(token_ids, token_type_ids, attn_masks).squeeze()\n",
        "\n",
        "      #Aggregate output batches (to calculate correlation over whole dataset later)\n",
        "      scores.append(batch_predict)\n",
        "      \n",
        "    \n",
        "  scores = torch.cat(scores)\n",
        "  \n",
        "  with open('predictions_finetuned.txt', 'w') as output_file:\n",
        "        for idx, x in enumerate(scores):\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIIHLn_7sELS",
        "colab_type": "code",
        "outputId": "b65b9cf0-2995-4d61-a6ef-637fc05cf829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Fine-tune on all available data\n",
        "model = MTQualityEstimator(freeze_bert = False)\n",
        "criterion = nn.MSELoss()\n",
        "epochs = 2\n",
        "optimizer = optim.AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "\n",
        "train(model, criterion, optimizer, epochs, traindev_loader)\n",
        "#Save predictions\n",
        "bert_predict_test(test_loader, model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 complete. Loss: 0.7028763084709644\n",
            "Epoch 1 complete. Loss: 0.6518015866279602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aJF6f1XM6Hd",
        "colab_type": "text"
      },
      "source": [
        "# Regression on pooled output (BERT weights frozen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0X-SU2g8wr6",
        "colab_type": "text"
      },
      "source": [
        "## Extract feature vector from [CLS]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWzBMefCSck5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pooled_representation(loader, bert):\n",
        "  pooled_rep=[]\n",
        "  bert.to('cuda')\n",
        "  bert.eval()  # set model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "    if loader.dataset.mode in ['train', 'dev']:\n",
        "      true_scores = []\n",
        "      for it, (token_ids, token_type_ids, attn_masks, batch_scores) in enumerate(loader):\n",
        "\n",
        "        #Converting to cuda tensors\n",
        "        token_ids, token_type_ids, attn_masks = token_ids.cuda(), token_type_ids.cuda(), attn_masks.cuda()\n",
        "\n",
        "        #Forward pass\n",
        "        _, batch_pooled_rep = bert(token_ids, token_type_ids = token_type_ids, attention_mask = attn_masks)\n",
        "\n",
        "        #Aggregate output batches (to calculate correlation over whole dataset later)\n",
        "        pooled_rep.append(batch_pooled_rep)\n",
        "        true_scores.append(batch_scores)\n",
        "\n",
        "      pooled_rep = torch.cat(pooled_rep)\n",
        "      true_scores = torch.cat(true_scores)\n",
        "\n",
        "      return pooled_rep.cpu().numpy(), true_scores.numpy()\n",
        "\n",
        "    else:\n",
        "      for it, (token_ids, token_type_ids, attn_masks) in enumerate(loader):\n",
        "\n",
        "        #Converting to cuda tensors\n",
        "        token_ids, token_type_ids, attn_masks = token_ids.cuda(), token_type_ids.cuda(), attn_masks.cuda()\n",
        "\n",
        "        #Forward pass\n",
        "        _, batch_pooled_rep = bert(token_ids, token_type_ids = token_type_ids, attention_mask = attn_masks)\n",
        "\n",
        "        #Aggregate output batches (to calculate correlation over whole dataset later)\n",
        "        pooled_rep.append(batch_pooled_rep)\n",
        "        \n",
        "      pooled_rep = torch.cat(pooled_rep)\n",
        "\n",
        "      return pooled_rep.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5Ns9H1U9Guy",
        "colab_type": "text"
      },
      "source": [
        "## Choose best regressor according to performance on validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ditT7r3kZeLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-multilingual-uncased')\n",
        "X_train, y_train = get_pooled_representation(train_loader, bert)\n",
        "X_val, y_val = get_pooled_representation(val_loader, bert)\n",
        "X_test = get_pooled_representation(test_loader, bert)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVRX9_KJWAiM",
        "colab_type": "code",
        "outputId": "a60d3e03-4d03-43e1-849c-ddb784b92aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "for name, regressor in zip(['Linear', 'Ridge', 'SVR linear', 'SVR rbf'], [LinearRegression(), Ridge(), SVR('linear'), SVR('rbf')]):\n",
        "    regressor.fit(X_train, y_train)\n",
        "    print(name)\n",
        "    predictions = regressor.predict(X_val)\n",
        "    pearson = pearsonr(y_val, predictions)\n",
        "    print(f'RMSE: {torch.sqrt(mse_loss(torch.tensor(y_val), torch.tensor(predictions)))} Pearson {pearson[0]}')\n",
        "    print()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear\n",
            "RMSE: 0.8962844473926784 Pearson 0.10672373789206752\n",
            "\n",
            "Ridge\n",
            "RMSE: 0.8554293837041853 Pearson 0.15613759681270084\n",
            "\n",
            "SVR linear\n",
            "RMSE: 0.8722189585388788 Pearson 0.12465365586565982\n",
            "\n",
            "SVR rbf\n",
            "RMSE: 0.8756795526767164 Pearson 0.12344757866176322\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZMu7dmx9S4v",
        "colab_type": "text"
      },
      "source": [
        "## Train with all available data and save the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1J6bSZvNrXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regressor_predict_test(regressor, X_train, y_train, X_test):\n",
        "  regressor.fit(X_train, y_train)\n",
        "  scores = regressor.predict(X_test)\n",
        "  with open('predictions_frozen.txt', 'w') as output_file:\n",
        "    for idx, x in enumerate(scores):\n",
        "        output_file.write(f\"{x}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BByHlnNSRmAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = np.concatenate([X_train, X_val], axis=0), np.concatenate([y_train, y_val], axis=0)\n",
        "regressor_predict_test(Ridge(), X, y, X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}